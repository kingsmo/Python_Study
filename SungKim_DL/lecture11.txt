11 - 1 Conv 레이어 만들기

여태까지는 forward 형식으로 진행

convolutional network
입력을 나누어 받는 것에서 아이디어를 얻음

하나의 이미지를
conv -> relu -> pool 여러번 반복
fc = fully connected label
로 점수로 어떤 이미지인지 판단

32 x 32 x 3 칼라이미지
5 x 5 x 3 필터
한번에 얼마나 보고싶은지 -> 5 x 5 만큼의 공간을 하나의 점으로 만들어냄
한 숫자를 Wx + b로 만들어냄 = ReLU(Wx + b)
똑같은 필터(w)를 가지고 다른 구역도 확인해야 한다.

이런식으로 진행하면 몇개의 값을 얻을 수 있냐?
예를 들어, stride가 1일 경우 7 x 7 에 3 x 3 필터 -> 5 x 5 output
stride가  2일 경우 3 x 3 output

N x N 입력 이미지
F 필터 크기 stride
간단한 식으로 만들면 (N - F) / stride + 1
ex) (7 - 3) / 2 + 1 = 3
큰 이미지가 점점 작아지게 됨 이미지 정보를 유실하게 됨

패딩이라는 개념을 사용한다.
테두리에다가 0으로 값을 두른다.
모서리라는 것을 알려두기 위해

7 x 7 이미지 3 x 3 필터 1 stride
with pad 1 pixel border -> 7 x 7 output
입력의 이미지와 출력의 이미지가 같게 해줌!

이것이 기본적으로 하나의 convolution한 것임 = conv 레이어


filter1, filter2 ... 각각의 필  터는 weight이 다름
(전체이미지, 필터사이즈, 아웃풋개수) = (28, 28, 6)

convolution한 것에 또 conv, relu 적용 가능

weight은 랜덤하게 초기화를 해주고 학습을 시켜주는 것이다.

11 - 2 convnet : max pooling full network

conv + relu 셋에 pool을 함
pooling layer = sampling = resize
종류로는 max pooling with 2 x 2 filters and stride 2
필터와 사이즈에 따라 정해질 것임

FC layer = Fully Connected Layer
conv, relu, pool 구성은 개발자 마음

11 - 3 Cnn 활용

convolutional neural network

alexnet
first layer 96개 필터 11 x 11 x 3  stride 4
35k만큼 필요
노멀라이제이션 레이어는 최근에 자주 쓰이지 않음
ReLU처음 씀
dropout
batchsize
7 cnn ensemble이 특징

GoogLeNet
inception module

ResNet
이미지 뿐만 아니라 다른 네트워크도 휩씀
152개의 layer를 사용
학습하기에 어려울꺼 같다.
fast forward방식으로 했음
레이어 개수는 크지만 실제로 학습할 때는 많이 하지 않음

sentence classfication

알파고 딥마인드
