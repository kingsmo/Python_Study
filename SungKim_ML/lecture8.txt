deep learning

1
사람과 비슷한 생각
뉴런의 동작이 단순한데 어떻게 생각?!
input * W + bias
돼서 합쳐짐
이 모여져 있는 값이 특정값 이상이되면 활성화
아니면 비활성화

2
이러한 뉴런의 원리를 이용해서 만들 수 있겠다
activation functions
합한값이 일정값을 넘어가면 output axon

3
여러개 인풋, 아웃풋으로 바꿔준 것 뿐
그다음 weight를 바꿔줌

4
and / or같은경우는 간단히 해결할 수 있음
lineary separable

5
xor은?
값이 다를때 1
값이 같으면 0
백프로 구분할 수 없다.

6
퍼셉트론
여러개 합치면(weight, bias)해결이 되지만
학습시킬수 없다.
다 이걸 믿어서 잠깐 ai가 후퇴됨

7
backpropagation
error를 이용하여 뒤에서부터 적용
82 paul werbos, 86년에 hinton
더 복잡한 문제 해결 가능

8
convolutional neural networks
부분부분으로 잘린다음 합치는 것
문자인식!

9
80년대에 자율주행 어느정도 수행가능

10
하지만 10여개 이상되는 layer를 학습시켜야 되는데
뒤에서 가는 것이 의미가 점점 약해서
학습이 안됨.
입력부분에선 중요
svm, random forest등 다른 알고리즘이 나옴

11
