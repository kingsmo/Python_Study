SoftMargin SVM

slack variable이 점점 커진다 margin에서 멀어질수록
hard는 infeasible하는 경우가 생김
constraint를 줌으로써 소프트하게 만듬

넘어간 정도가 알아서 패널티 되니까 알아서 모델링 해라.

hinge loss
logistic function : Log Loss 펑션을 쓴다.(파란색)

log loss가 무조건 좋아보이지만
svm은 완전히 갈리는 상황을 가정하니까
log loss가 안전한 곳에 있을지라도 패널티를 주고 있는 문제가 있다.
급격한 패널티를 주기위한 loss function이다.
문제에 맞춰 머신러닝 알고리즘을 택하는 것이 중요

c를 어떻게 결정하느냐에 따라 성능이 많이 달라질 것이다.
c값이 낮으면 penalization이 적어 decision boundary가 영향이 약해짐
정해진 데이터에는 무조건 큰 c값을 정하는 게 좋지만
미래에 들어올 데이터 셋에는 그것이 좋을지는 아직 잘 모른다. 
