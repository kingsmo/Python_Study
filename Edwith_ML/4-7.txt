Naive Bayes to Logistic Regression

강한 hypothesis 만들기
데이터 셋을 기반으로 파라미터들을 최적화시켜주는 것이 learning과정

naive bayes와 logistic regression의 비교가 중점
나이브 베이즈를 continuous feature들로 다룬다.
예전에는 catrgorical -> numerical하게 바꿔야 compatible할 수 있다.
가우시안 분포
특정 클래스에 대해서 mean과 variance를 볼 수 있다.
mean과 variance로 표현한 gaussian형태로 바꾼다.

나이브 베이즈에서 로지스틱 리그레션으로 유도
generative discriminitive pair 로 불림
discriminitive는 바로 구하는 것 - logistic regression - MLE
제너러티브는 베이즈 정리를 이용해서 prior likelihood를 이용 - MAP

이것을 유도하겠다
X가 피쳐개수가 exponential growth해서 개별피쳐에 해당하는 프로젝션으로 바꿈
이제 여기다가 가우시안 분포를 따르는 것으로 체인지
분산텀이 양쪽 클래스에서 같다고 가정하고
